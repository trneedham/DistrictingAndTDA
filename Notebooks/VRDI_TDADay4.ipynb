{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDA on Adjacency Networks\n",
    "\n",
    "Our goal is to extract adjacency networks from shapefiles of districting data. We will then define filtration functions and filtered simplicial complexes on top of these adjacency networks. This notebook will require the TDA package `gudhi`. Instructions for installing this via `conda` can be found here: https://anaconda.org/conda-forge/gudhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import networkx as nx\n",
    "\n",
    "from gerrychain import MarkovChain\n",
    "from gerrychain.constraints import (\n",
    "    Validator,\n",
    "    single_flip_contiguous,\n",
    "    within_percent_of_ideal_population,\n",
    ")\n",
    "from gerrychain.proposals import propose_random_flip\n",
    "from gerrychain.accept import always_accept\n",
    "from gerrychain.updaters import Election, Tally, cut_edges\n",
    "from gerrychain.partition import Partition\n",
    "from gerrychain.proposals import recom\n",
    "from gerrychain.metrics import mean_median, efficiency_gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example\n",
    "\n",
    "Let's start with a basic graph to get things running (this is taken from the \"GridChainSimple\" notebook in this repository: https://github.com/drdeford/GerryChain-Templates)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Graph\n",
    "\n",
    "We will create a rectangular grid with all \"rook adjacent\" neighbors connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_districts = 7\n",
    "factor = 5\n",
    "# The grid will be square with num_districts*factor nodes per dimension\n",
    "node_size = 20\n",
    "p = 0.5 # Probability voter is in group 'pin'\n",
    "\n",
    "graph = nx.grid_graph([num_districts * factor, num_districts * factor])\n",
    "\n",
    "\n",
    "for n in graph.nodes():\n",
    "    graph.node[n][\"population\"] = 1\n",
    "\n",
    "    if random.random() < p:\n",
    "        graph.node[n][\"pink\"] = 1\n",
    "        graph.node[n][\"purple\"] = 0\n",
    "    else:\n",
    "        graph.node[n][\"pink\"] = 0\n",
    "        graph.node[n][\"purple\"] = 1\n",
    "    if 0 in n or num_districts * factor - 1 in n:\n",
    "        graph.node[n][\"boundary_node\"] = True\n",
    "        graph.node[n][\"boundary_perim\"] = 1\n",
    "\n",
    "    else:\n",
    "        graph.node[n][\"boundary_node\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a districting plan. We just cut the grid into columns of width 'factor' to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cddict = {x: int(x[0] / factor) for x in graph.nodes()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot grids\n",
    "\n",
    "Now we use `neworkx` functions to plot our graph. In particular, we plot:\n",
    "\n",
    "- Basic grid graph\n",
    "- Grid graph with voter labels\n",
    "- Grid graph with districts drawn in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,5))\n",
    "\n",
    "# Plot the basic graph\n",
    "fig.add_subplot(1,3,1)\n",
    "nx.draw(graph, pos={x: x for x in graph.nodes()}, node_size=node_size, node_shape=\"s\")\n",
    "\n",
    "# Plot the graph with voter labels\n",
    "cdict = {1: \"pink\", 0: \"purple\"}\n",
    "\n",
    "fig.add_subplot(1,3,2)\n",
    "nx.draw(\n",
    "    graph,\n",
    "    pos={x: x for x in graph.nodes()},\n",
    "    node_color=[cdict[graph.node[x][\"pink\"]] for x in graph.nodes()],\n",
    "    node_size=node_size,\n",
    "    node_shape=\"s\",\n",
    ")\n",
    "\n",
    "\n",
    "# Plot the graph with district labels\n",
    "fig.add_subplot(1,3,3)\n",
    "nx.draw(\n",
    "    graph,\n",
    "    pos={x: x for x in graph.nodes()},\n",
    "    node_color=[cddict[x] for x in graph.nodes()],\n",
    "    node_size=node_size,\n",
    "    node_shape=\"s\",\n",
    "    cmap=\"tab20\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a Markov Chain\n",
    "\n",
    "Now we'll take our basic districting plan as a seed and run the Markov chain on it to produce a random district. This is done using the `gerrychain` package with the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Updaters\n",
    "\n",
    "The `updaters` keep track of geometric and demographic features at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_num(partition):\n",
    "    parent = partition.parent\n",
    "    if not parent:\n",
    "        return 0\n",
    "    return parent[\"step_num\"] + 1\n",
    "\n",
    "\n",
    "updaters = {\n",
    "    \"population\": Tally(\"population\"),\n",
    "    \"cut_edges\": cut_edges,\n",
    "    \"step_num\": step_num,\n",
    "    \"Pink-Purple\": Election(\"Pink-Purple\", {\"Pink\": \"pink\", \"Purple\": \"purple\"}),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Partition\n",
    "\n",
    "`Partition` class keeping track of the underlying graph, the district reassignment at each step and all of the `updaters` information at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_partition = Partition(graph, assignment=cddict, updaters=updaters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constraints\n",
    "\n",
    "Put constraints on the Markov chain updates. Here we declare that the population in each district has to be within `percentage` percent of the ideal (equal population in every district)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 0.1\n",
    "popbound = within_percent_of_ideal_population(grid_partition, percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposal function\n",
    "\n",
    "We use the proposal function to define new partitions at each step. It will enforce our constraint at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ideal population is to have an equal number of voters per district\n",
    "ideal_population = sum(grid_partition[\"population\"].values()) / len(grid_partition)\n",
    "\n",
    "tree_proposal = partial(\n",
    "    recom,\n",
    "    pop_col=\"population\",\n",
    "    pop_target=ideal_population,\n",
    "    epsilon=0.05,\n",
    "    node_repeats=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Markov Chain Class\n",
    "\n",
    "We'll use the `recom_chain` method via `tree_proposal` defined above. Change the number of steps here to allow more mixing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom_chain = MarkovChain(\n",
    "    tree_proposal,\n",
    "    Validator([popbound]),\n",
    "    accept=always_accept,\n",
    "    initial_state=grid_partition,\n",
    "    total_steps=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Markov Chain\n",
    "\n",
    "This will keep track of the various statistics at each step in the walk. We run the walk then plot the resulting districting plus plots of the various statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rsw = [] # Number of district won by 'Pink' voters\n",
    "rmm = [] \n",
    "reg = [] # Efficiency gap\n",
    "rce = []\n",
    "\n",
    "for part in recom_chain:\n",
    "    rsw.append(part[\"Pink-Purple\"].wins(\"Pink\"))\n",
    "    rmm.append(mean_median(part[\"Pink-Purple\"]))\n",
    "    reg.append(efficiency_gap(part[\"Pink-Purple\"]))\n",
    "    rce.append(len(part[\"cut_edges\"]))\n",
    "\n",
    "plt.figure()\n",
    "nx.draw(\n",
    "    graph,\n",
    "    pos={x: x for x in graph.nodes()},\n",
    "    node_color=[dict(part.assignment)[x] for x in graph.nodes()],\n",
    "    node_size=node_size,\n",
    "    node_shape=\"s\",\n",
    "    cmap=\"tab20\",\n",
    ");\n",
    "\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "fig.add_subplot(1,4,1)\n",
    "plt.plot(rsw);\n",
    "\n",
    "fig.add_subplot(1,4,2)\n",
    "plt.plot(rmm);\n",
    "\n",
    "fig.add_subplot(1,4,3)\n",
    "plt.plot(reg);\n",
    "\n",
    "fig.add_subplot(1,4,4)\n",
    "plt.plot(rce);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjacency Network\n",
    "\n",
    "Now let's get the adjacency network for our new districting. We will have a node for each district. Nodes are connected in the adjacency matrix if they are connected by a cut edge. \n",
    "\n",
    "We first define a function to extract the district pairs (based on presence of a cut edge between them) from a partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def district_pairs(part):\n",
    "    pairs = []\n",
    "    for x, y in part['cut_edges']:\n",
    "        pairs.append((part.assignment[x],part.assignment[y]))\n",
    "    return set(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function which takes a partition and produces an adjacency graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_graph_cut_edges(part):\n",
    "    edges = district_pairs(part)\n",
    "    adjacency_graph = nx.Graph()\n",
    "    adjacency_graph.add_nodes_from(list({x for (x,y) in edges}))\n",
    "    adjacency_graph.add_edges_from(list(edges))\n",
    "    return adjacency_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw the results to see if they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,5))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "\n",
    "nx.draw(\n",
    "    graph,\n",
    "    pos={x: x for x in graph.nodes()},\n",
    "    node_color=[dict(part.assignment)[x] for x in graph.nodes()],\n",
    "    node_size=node_size,\n",
    "    node_shape=\"s\",\n",
    "    cmap=\"tab20\",\n",
    ");\n",
    "\n",
    "plt.title('Districting Plan');\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "nx.draw_networkx(adjacency_graph_cut_edges(part), \n",
    "                 node_color = [x for x in adjacency_graph_cut_edges(part).nodes()], \n",
    "                 cmap=\"tab20\")\n",
    "plt.title('Cut Edges Adjacency Graph');\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtration Function\n",
    "\n",
    "We will also want to keep track of various numbers which we think of as weights on the vertices or edges. For example, we could keep track of the 'Pink' voting percentage in each district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink_voter_share = part[\"Pink-Purple\"].percents(\"Pink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink_voter_share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Filtration on the Adjacency Graph\n",
    "\n",
    "Now let's import some software to do topological data analysis on the adjacency graph. The TDA software we will use here is the `gudhi` package. The package is quite flexible in that it allows us to define custom filtrations on a simplicial complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gudhi as gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix an adjacency graph to run the computations on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_graph = adjacency_graph_cut_edges(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplex Tree\n",
    "\n",
    "We first turn the adjacency graph into a simplicial complex. In `gudhi`, a simplicial complex is represented as a datatype called a `SimplexTree`. It is simply an efficient way to store a simplicial complex, introduced here: https://link.springer.com/article/10.1007/s00453-014-9887-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a simplicial complex from our adjacency graph, we start with an 'empty simplicial complex', then add in the edges. Vertices will be added automatically, so that we are really describing an honest simplicial complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with an empty simplex tree\n",
    "spCpx = gd.SimplexTree()\n",
    "\n",
    "# Add edges from the adjacency graph\n",
    "for edge in adjacency_graph.edges:\n",
    "    spCpx.insert(list(edge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the simplices in our complex as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spCpx_list = spCpx.get_filtration() \n",
    "\n",
    "for splx in spCpx_list :\n",
    "    print(splx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pause for a second here to understand this output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the number `0.0` assigned to each simplex. This is the *filtration value*, thinking of our object as a *filtered simplicial complex*. We can change these filtration values as follows. We will use `pink_voter_share` as our filtration function on the vertices --- one thing that's great about the `gudhi` packages is that it allows us to use any filtration function we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by adding the appropriate filtration value to each vertex of the simplicial complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_skeleton = spCpx.get_skeleton(0)\n",
    "\n",
    "for j in range(len(zero_skeleton)):\n",
    "    spCpx.assign_filtration(zero_skeleton[j][0], filtration=pink_voter_share[j])\n",
    "    \n",
    "spCpx_list = spCpx.get_filtration() \n",
    "for splx in spCpx_list:\n",
    "    print(splx)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the adjacency network with nodes colored by their filtration values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(adjacency_graph, node_color=pink_voter_share, cmap=plt.cm.Blues)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning the function only on the vertices doesn't produce a valid filtered simplicial complex: edges arrive earlier in the filtration than their endpoints! There is a function to fix this called `make_filtration_non_decreasing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spCpx.make_filtration_non_decreasing()\n",
    "spCpx_list = spCpx.get_filtration()\n",
    "for splx in spCpx_list:\n",
    "    print(splx) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a filtered simplicial complex, to which we can apply persistent homology. Here we are computing the $0$-dimensional persistent homology. That is, we are looking at persistent *connected components* in the simplicial complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BarCodes = spCpx.persistence()\n",
    "BarCodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot a barcode or a persistence diagram from our persistent homology computation.\n",
    "\n",
    "#### Disclaimer:\n",
    "\n",
    "This data is randomized, so when you run it you might get a single bar in your barcode. In this case, the persistence diagram plot might look weird!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.plot_persistence_barcode(BarCodes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd.plot_persistence_diagram(BarCodes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Compare these plots with the plot of the adjacency network with filtration values. Stare at these outputs until they make sense.\n",
    "\n",
    "Try running everything again with a different random districting plan. You can play with parameters to produce more districts and get more complicated adjacency graphs or a different voter distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Real Districting Data\n",
    "\n",
    "### Importing and Creating Data\n",
    "\n",
    "Now we will import some real districting plans for Pennsylvania and create some plans via the tree recombination algorithm. The first part of the code is from the `Day1` section in this repository: https://github.com/vrdi/GerryChain-BootCamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from functools import partial\n",
    "import json\n",
    "import networkx as nx\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gerrychain import (\n",
    "    Election,\n",
    "    Graph,\n",
    "    MarkovChain,\n",
    "    Partition,\n",
    "    accept,\n",
    "    constraints,\n",
    "    updaters,\n",
    ")\n",
    "from gerrychain.metrics import efficiency_gap, mean_median\n",
    "from gerrychain.proposals import recom\n",
    "from gerrychain.updaters import cut_edges\n",
    "from gerrychain.tree import recursive_tree_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdir = \"./Outputs/\"\n",
    "os.makedirs(os.path.dirname(newdir + \"init.txt\"), exist_ok=True)\n",
    "with open(newdir + \"init.txt\", \"w\") as f:\n",
    "    f.write(\"Created Folder\")\n",
    "\n",
    "\n",
    "graph_path = \"./Data/PA_VTDALL.json\"  # \"./Data/PA_BPOP_FINAL/VTD_FINAL.shp\"\n",
    "plot_path = \"./Data/VTD_FINAL.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file(plot_path)\n",
    "\n",
    "\n",
    "unique_label = \"GEOID10\"\n",
    "pop_col = \"TOT_POP\"\n",
    "district_col = \"2011_PLA_1\"\n",
    "county_col = \"COUNTYFP10\"\n",
    "\n",
    "num_elections = 3\n",
    "\n",
    "\n",
    "election_names = [\n",
    "    \"PRES12\",\n",
    "    \"PRES16\",\n",
    "    \"SENW101216\",\n",
    "]\n",
    "election_columns = [\n",
    "    [\"PRES12D\", \"PRES12R\"],\n",
    "    [\"T16PRESD\", \"T16PRESR\"],\n",
    "    [\"W101216D\", \"W101216R\"],\n",
    "]\n",
    "\n",
    "\n",
    "graph = Graph.from_json(graph_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define updaters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updaters = {\n",
    "    \"population\": updaters.Tally(\"TOT_POP\", alias=\"population\"),\n",
    "    \"cut_edges\": cut_edges,\n",
    "}\n",
    "\n",
    "elections = [\n",
    "    Election(\n",
    "        election_names[i],\n",
    "        {\"Democratic\": election_columns[i][0], \"Republican\": election_columns[i][1]},\n",
    "    )\n",
    "    for i in range(num_elections)\n",
    "]\n",
    "\n",
    "election_updaters = {election.name: election for election in elections}\n",
    "\n",
    "updaters.update(election_updaters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at some 'premade' partitions. In particular, `partition_2011` is the real districting plan from 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_2011 = Partition(graph, \"2011_PLA_1\", updaters)\n",
    "partition_GOV = Partition(graph, \"GOV\", updaters)\n",
    "partition_TS = Partition(graph, \"TS\", updaters)\n",
    "partition_REMEDIAL = Partition(graph, \"REMEDIAL_P\", updaters)\n",
    "partition_CPCT = Partition(graph, \"538CPCT__1\", updaters)\n",
    "partition_DEM = Partition(graph, \"538DEM_PL\", updaters)\n",
    "partition_GOP = Partition(graph, \"538GOP_PL\", updaters)\n",
    "partition_8th = Partition(graph, \"8THGRADE_1\", updaters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define 5 random plans by making cuts according to the spanning tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_partitions = []\n",
    "\n",
    "tree_plans = 5\n",
    "n_base_plans = 8\n",
    "\n",
    "for i in range(tree_plans):\n",
    "    print('Finished tree plan', i)\n",
    "    cddict = recursive_tree_part(graph, range(18), df[\"TOT_POP\"].sum() / 18, \"TOT_POP\", .01, 1)\n",
    "    tree_partitions.append(Partition(graph, cddict, updaters))\n",
    "\n",
    "partition_list = [partition_2011, partition_GOV, partition_TS,\n",
    "                  partition_REMEDIAL, partition_CPCT, partition_DEM,\n",
    "                  partition_GOP, partition_8th]\n",
    "\n",
    "partition_list = partition_list + tree_partitions\n",
    "\n",
    "n_plans = tree_plans + n_base_plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_edges_metric(part):\n",
    "    return len(part[\"cut_edges\"])\n",
    "\n",
    "\n",
    "print(\"The 2011 plan has\", cut_edges_metric(partition_2011) , \"cut edges.\")\n",
    "print(\"The GOV plan has\", cut_edges_metric(partition_GOV), \"cut edges.\")\n",
    "print(\"The TS plan has\", cut_edges_metric(partition_TS), \"cut edges.\")\n",
    "print(\"The REMEDIAL plan has\", cut_edges_metric(partition_REMEDIAL), \"cut edges.\")\n",
    "print(\"The 538 Compact plan has\", cut_edges_metric(partition_CPCT), \"cut edges.\")\n",
    "print(\"The 538 DEM plan has\", cut_edges_metric(partition_DEM), \"cut edges.\")\n",
    "print(\"The 538 GOP plan has\", cut_edges_metric(partition_GOP), \"cut edges.\")\n",
    "print(\"The 8th grade plan has\", cut_edges_metric(partition_8th), \"cut edges.\")\n",
    "\n",
    "for i in range(tree_plans):\n",
    "    print(\"Tree plan\", i + 1, \"cut edges:\" , cut_edges_metric(tree_partitions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "ys = [cut_edges_metric(part) for part in partition_list]\n",
    "\n",
    "plt.plot(ys, 'o', color='hotpink', markersize=20);\n",
    "\n",
    "plt.ylabel(\"# of cut edges\");\n",
    "\n",
    "labels = ['2011', 'GOV', 'TS', 'REMEDIAL', 'CPCT', 'DEM', 'GOP', '8th'] + [\"Tree\" + str(k + 1) for k in range(tree_plans)];\n",
    "\n",
    "plt.xticks(range(len(labels)), labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDA on the Adjacency Networks\n",
    "\n",
    "Now we can:\n",
    "\n",
    "- Create adjacency networks for each partition\n",
    "- Filter by Democratic voter share (or any other function of the district demographics that we find interesting)\n",
    "- Compute persistent homology and persistence diagrams\n",
    "\n",
    "Do the results have any interesting interpretations? \n",
    "\n",
    "#### Disclaimer\n",
    "\n",
    "`gudhi` might give some warnings if your persistence diagrams consist of only a single point. This is not anything to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in range(13):\n",
    "    part = partition_list[k]\n",
    "\n",
    "    adjacency_graph = adjacency_graph_cut_edges(part)\n",
    "\n",
    "    spCpx = gd.SimplexTree()\n",
    "    for edge in adjacency_graph.edges:\n",
    "        spCpx.insert(list(edge))\n",
    "\n",
    "    Democratic_voter_share = part['PRES12'].percents('Democratic')\n",
    "\n",
    "    zero_skeleton = spCpx.get_skeleton(0)\n",
    "\n",
    "    for j in range(len(zero_skeleton)):\n",
    "        spCpx.assign_filtration(zero_skeleton[j][0], filtration=Democratic_voter_share[j])\n",
    "\n",
    "    spCpx.make_filtration_non_decreasing()\n",
    "\n",
    "    BarCodes = spCpx.persistence()\n",
    "\n",
    "    fig = plt.figure(figsize = (10,5))\n",
    "\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    nx.draw_networkx(adjacency_graph, node_color=Democratic_voter_share, cmap=plt.cm.Blues)\n",
    "    plt.title('Partition '+labels[k])\n",
    "    ax.axis('off')\n",
    "\n",
    "    fig.add_subplot(1,2,2)\n",
    "    gd.plot_persistence_diagram(BarCodes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Study the output filtered adjacency networks and persistence diagrams. Do you notice any qualitative trends?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck Distance Between the Adjacency Networks\n",
    "\n",
    "Now let's compare these persistence diagrams more quantitatively. First we store the simplicial complexes in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_spCpx = []\n",
    "\n",
    "for k in range(13):\n",
    "    part = partition_list[k]\n",
    "\n",
    "    adjacency_graph = adjacency_graph_cut_edges(part)\n",
    "\n",
    "    spCpx = gd.SimplexTree()\n",
    "    for edge in adjacency_graph.edges:\n",
    "        spCpx.insert(list(edge))\n",
    "    \n",
    "    Democratic_voter_share = part['PRES12'].percents('Democratic')\n",
    "    \n",
    "    zero_skeleton = spCpx.get_skeleton(0)\n",
    "\n",
    "    for j in range(len(zero_skeleton)):\n",
    "        spCpx.assign_filtration(zero_skeleton[j][0], filtration=Democratic_voter_share[j])\n",
    "\n",
    "    spCpx.make_filtration_non_decreasing()\n",
    "\n",
    "    partitions_spCpx.append(spCpx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a distance matrix containing the bottleneck distance between any pair of barcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distMat = np.zeros((13,13))\n",
    "\n",
    "for j in range(13):\n",
    "    for k in range(13):\n",
    "        spCpx0 = partitions_spCpx[j]\n",
    "        spCpx1 = partitions_spCpx[k]\n",
    "        \n",
    "        spCpx0.persistence()\n",
    "        spCpx1.persistence()\n",
    "\n",
    "        I0 = spCpx0.persistence_intervals_in_dimension(0)\n",
    "        I1 = spCpx1.persistence_intervals_in_dimension(0)\n",
    "\n",
    "        distMat[j,k] = gd.bottleneck_distance(I0,I1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We view the distance matrix as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distMat);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the shape of the 'space of districting plans', we can use Multi-Dimensional Scaling. This algorithm looks for the set of points in $\\mathbb{R}^2$ (or $\\mathbb{R}^3$) whose distance matrix is as close as possible to the distance matrix we just computed. For a more precise description, go here: https://en.wikipedia.org/wiki/Multidimensional_scaling\n",
    "\n",
    "The result gives us a visualization of how similar the districting plans are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import a package containing the MDS algorithm and set options for the algorithm\n",
    "from sklearn import manifold\n",
    "mds = manifold.MDS(n_components=2, dissimilarity=\"precomputed\")\n",
    "\n",
    "# Compute MDS and extract the coordinates of the points\n",
    "results = mds.fit(distMat)\n",
    "coords = results.embedding_\n",
    "\n",
    "z = coords[:,0]\n",
    "y = coords[:,1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(z, y)\n",
    "\n",
    "for i, txt in enumerate(labels):\n",
    "    ax.annotate(txt, (z[i], y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use MDS to project the data to 3D. It takes a little more work to make the plot. You can try running this a few times; MDS doesn't have a unique answer and the algorithm involves some randomness, so you will get something different every time you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "mds = manifold.MDS(n_components=3, dissimilarity=\"precomputed\")\n",
    "results = mds.fit(distMat)\n",
    "coords = results.embedding_\n",
    "\n",
    "fig = plt.figure(figsize = (7,7))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "for i, txt in enumerate(labels):\n",
    "    ax.scatter(coords[i,0],coords[i,1],coords[i,2]) \n",
    "    ax.text(coords[i,0],coords[i,1],coords[i,2],  '%s' % (txt), size=10, zorder=1) \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "What does this figure suggest to you about the districting plans?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Try other stuff! Here are some ideas:\n",
    "\n",
    "- Define other filtration functions on the networks and rerun the above computations. You could also filter by other demographic information, use the Feng-Porter filtration function, use weighted sums of functions etc.\n",
    "- Specifically, try filtering by Republican voter share. Do you get anything much different in the MDS plots? Should you expect to?\n",
    "- Define a metric on the adjacency network and use the Vietoris-Rips to filter it. This functionality is built into `gudhi`, but you will have to dig through the documentation a bit to figure out how to do it: http://gudhi.gforge.inria.fr/ripscomplex/\n",
    "- Run similar experiments on districting plans for other states.\n",
    "- Pick a couple of different seeds, run Markov chains to generate Markov chains with these seeds. Do the plans coming from the different seeds stay near their seeds (measured via bottleneck distance for their adjacency networks)? This could give a picture of the mixing behavior of this Markov chain. \n",
    "- Generalize this to run on more complicated adjacency networks, such as those that were considered in Feng-Porter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
