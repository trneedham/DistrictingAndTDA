{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Topological Data Analysis, Part II\n",
    "\n",
    "In this notebook we will focus on methods for comparing topological signatures. We will try an application to shape matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages for TDA and scientific computing\n",
    "from ripser import ripser\n",
    "from ripser import Rips\n",
    "import persim\n",
    "from persim import PersImage\n",
    "from persim import plot_diagrams \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from math import ceil\n",
    "import time\n",
    "\n",
    "# Import packages for loading .mat files\n",
    "import os \n",
    "from os.path import dirname, join as pjoin\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Computing Persistence Diagrams, Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "r = 5\n",
    "R = 10\n",
    "\n",
    "theta = 2*np.pi*np.random.rand(N)\n",
    "phi = 2*np.pi*np.random.rand(N)\n",
    "X = (R + r * np.cos(phi)) * np.cos(theta)\n",
    "Y = (R + r * np.cos(phi)) * np.sin(theta) \n",
    "Z = r *  np.sin(phi)\n",
    "pointCloud = np.append(X.reshape(N,1),Y.reshape(N,1),axis =1)\n",
    "pointCloud = np.append(pointCloud,Z.reshape(N,1), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = fig.gca(projection='3d', adjustable='box')\n",
    "ax.scatter(pointCloud[:,0],pointCloud[:,1],pointCloud[:,2], c='b', marker='o');\n",
    "# The following command doesn't seem to work here... I believe this is a known issue with matplotlib\n",
    "ax.set_aspect('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `ripser`, we compute the persistent homology of our point cloud and plot the resulting persistence diagrams. We only compute homology up to degree-1 for the sake of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms = ripser(pointCloud)['dgms']\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plot_diagrams(dgms, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the output make sense? How does it change if we play with the parameters in the creation of our point cloud?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Bottleneck Distance and Shape Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load the data set. The data consists of a large number of densely sampled plane curves representing various objects (bones, dogs, cars, etc.). The file is a .mat file, which we read into Python with the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd() # Get the current working directory name.\n",
    "mat_fname = pjoin(data_dir, 'planarShapes.mat') \n",
    "# Add the file name to the current working directory.\n",
    "\n",
    "mat_contents = sio.loadmat(mat_fname) # Read the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what is contained in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we need to separate the actual data from the metadata. The types of data in the file are listed under several \"keys\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plane curves we are after are under the 'planarShapes' key. Let's extract that from the mat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planarShapes = mat_contents['planarShapes']\n",
    "planarShapes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second command above shows that planarShapes is a 2x100x1300 array. Exploring more, we would find that there are 1300 separate shapes, separated into 20 copies of similar shapes (so 65 classes of similar shapes). Each of the 1300 shapes is a pointcloud in $\\mathbb{R}^2$ consisting of 100 points. Let's plot a couple of the shapes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shape_indices = [4*x for x in range(25)]\n",
    "\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "\n",
    "for j in range(25):\n",
    "    ax = fig.add_subplot(5,5,j+1)\n",
    "    shape = planarShapes[:,:,shape_indices[j]]\n",
    "    ax.plot(shape[0,:], shape[1,:], linewidth=3)\n",
    "    ax.axis('off')\n",
    "    ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code plots the shapes as continuous curves, but the data for each shape is really a point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "shape = planarShapes[:,:,4]\n",
    "plt.scatter(shape[0,:], shape[1,:])\n",
    "plt.axis('off')\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Experiments with Bottleneck Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix some shapes to use for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_indices = [1,125,127] # Pick some shapes.\n",
    "\n",
    "num_shapes = len(shape_indices) \n",
    "# If you want to pick different shape indices it will be useful to save this as variable.\n",
    "\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "\n",
    "for j in range(num_shapes):\n",
    "    ax = fig.add_subplot(1,3,j+1)\n",
    "    shape = planarShapes[:,:,shape_indices[j]]\n",
    "    ax.plot(shape[0,:], shape[1,:], linewidth=3)\n",
    "    ax.axis('off')\n",
    "    plt.title('Shape '+str(j))\n",
    "    ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute persistence diagrams for these examples, then look at bottleneck distances between them. Note that ripser prefers the pointclouds to be transposed. I.e., shape1 is given as a 2x100 array, but ripser wants to see a 100x2 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeDgms = [ripser(planarShapes[:,:,shape_indices[j]].T)['dgms'] for j in range(num_shapes)]\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "for j in range(num_shapes):\n",
    "    ax = fig.add_subplot(1,num_shapes,j+1) # You might need to change this layout if you change shape_indices\n",
    "    plt.title('PD for Shape '+str(j))\n",
    "    plot_diagrams(shapeDgms[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"persim\" package includes several distance metrics between persistence diagrams, including the bottleneck distance that we have defined in class. Let's compute bottleneck distances between our shape examples. There is an option to not only compute the distance, but to record the optimal matching which produces it. In the first example, we compute the bottleneck distance between the degree-1 persistence diagrams for shapes with indices 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_bottleneck, (matching, D) = persim.bottleneck(shapeDgms[0][1], shapeDgms[1][1], matching=True)\n",
    "print(distance_bottleneck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the persistence diagrams on the same axes and display the optimal matching. The green line segment indicates matched points incurring the highest cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persim.plot.bottleneck_matching(shapeDgms[0][1], shapeDgms[1][1], matching, D, labels=['shape0', 'shape1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compute the distance between shapes with indices 0 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_bottleneck, (matching, D) = persim.bottleneck(shapeDgms[0][1], shapeDgms[2][1], matching=True)\n",
    "print(distance_bottleneck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "persim.plot.bottleneck_matching(shapeDgms[0][1], shapeDgms[2][1], matching, D, labels=['shape0', 'shape2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the distance between shapes 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_bottleneck, (matching, D) = persim.bottleneck(shapeDgms[1][1], shapeDgms[2][1], matching=True)\n",
    "print(distance_bottleneck)\n",
    "\n",
    "persim.plot.bottleneck_matching(shapeDgms[1][1], shapeDgms[2][1], matching, D, labels=['shape1', 'shape2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So bottleneck distance seems to pick up on differences in the shapes. We can summarize the distances by computing a *distance matrix*. Since we are comparing 3 shapes, the distance matrix will be a $3 \\times 3$ matrix whose $(i,j)$-entry is the bottleneck distance between Shape $i$ and Shape $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distance matrix\n",
    "distMat = np.zeros((3,3))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        distMat[i,j] = persim.bottleneck(shapeDgms[i][1], shapeDgms[j][1], matching=True)[0]\n",
    "        \n",
    "# Display the distance matrix\n",
    "img = plt.imshow(distMat)\n",
    "img.set_cmap('hot')\n",
    "plt.colorbar()\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Experiment\n",
    "\n",
    "Let's now try a more serious supervised learning experiment. We'll pick several shape classes, then several examples of shapes from each class. The goal is to see whether bottleneck distance between persistence diagrams will work as a classifier for the shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_classes = [100,200,300,400,500,600,700,800] # Pick indices of shape classes to sample.\n",
    "num_classes = len(shape_classes)\n",
    "num_shapes = 16\n",
    "# Pick number of examples to take from each shape class\n",
    "# Pick carefully so that we get shapes from the same class!\n",
    "# Remember the shapes come in groups of 20\n",
    "\n",
    "# Create labels for the data\n",
    "labels = []\n",
    "\n",
    "for j in range(num_classes):\n",
    "    labels = labels + num_shapes*[j]\n",
    "\n",
    "# List all indices of the shape samples for the experiment.\n",
    "samples =[]\n",
    "for j in range(num_classes):\n",
    "    samples = samples+range(shape_classes[j],shape_classes[j]+num_shapes)\n",
    "\n",
    "# We now pick out the shapes with indices in 'samples' and preprocess.\n",
    "num_samp = len(samples)\n",
    "\n",
    "shapeSamples = [planarShapes[:,:,samples[j]].T for j in range(num_samp)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at shapes from each of the shape classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "for j in range(num_classes):\n",
    "    shape_example = shapeSamples[j*num_shapes]\n",
    "    ax = fig.add_subplot(1,num_classes,j+1)\n",
    "    ax.plot(shape_example[:,0], shape_example[:,1], linewidth = 3)\n",
    "    plt.title('Shape Class '+str(j))\n",
    "    ax.axis('off')\n",
    "    ax.axis('equal')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at the samples within a given class of shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,2))\n",
    "\n",
    "for j in range(num_shapes):\n",
    "    shape_example = shapeSamples[j]\n",
    "    ax = fig.add_subplot(2,int(ceil(num_shapes)/2),j+1)\n",
    "    ax.plot(shape_example[:,0], shape_example[:,1], linewidth = 3)\n",
    "    ax.axis('off')\n",
    "    ax.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compute persistence diagrams for each of the shapes in our sampled collection. We are using the standard options for ripser, which will compute degree-0 and degree-1 persistence diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeSamplesDgms = [ripser(shapeSamples[j])['dgms'] for j in range(num_samp)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute bottleneck distances between all pairs of persistence diagrams. We computed persistence diagrams for degree-0 and degree-1 persistent homology in the previous cell, so we could compute bottleneck distances in each degree.\n",
    "\n",
    "It takes quite a while to run the degree-0 computation. It is commented out in the cell below because I don't want to run it in class. Feel free to uncomment and try it yourself.\n",
    "\n",
    "In the cell below that, we compute the distance matrix for the degree-1 persistence diagrams. Note that, if there are N total shape samples, then this distance matrix should be an NxN symmetric matrix. The $(i,j)$-entry is the bottleneck distance between the persistence diagram of shape $i$ and shape $j$. We are really thinking of each shape as a point in a metric space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell and run it if you want to!\n",
    "\n",
    "#distMatDeg0 = np.zeros([num_samp,num_samp])\n",
    "\n",
    "#for j in range(num_samp):\n",
    "#    for k in range(j+1,num_samp):\n",
    "#        distMatDeg0[j,k] = persim.bottleneck(shapeSamplesDgms[j][0], shapeSamplesDgms[k][0])\n",
    "#    print(j)\n",
    "\n",
    "#distMatDeg0 = distMatDeg0 + np.transpose(distMatDeg0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distMatDeg1 = np.zeros([num_samp,num_samp])\n",
    "\n",
    "for j in range(num_samp):\n",
    "    for k in range(j+1,num_samp):\n",
    "        distMatDeg1[j,k] = persim.bottleneck(shapeSamplesDgms[j][1], shapeSamplesDgms[k][1])\n",
    "\n",
    "distMatDeg1 = distMatDeg1 + np.transpose(distMatDeg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the structure of our metric space, we can take a look at the distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(distMatDeg1)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use *multidimensional scaling (MDS)* to get a feel for why each metric does a good/bad job. MDS attempts to embed the metric space defined by each distance matrix into $\\mathbb{R}^2$ or $\\mathbb{R}^3$ (this is chosen by the user), in order to visualize clustering behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a package containing the MDS algorithm and set options for the algorithm\n",
    "from sklearn import manifold\n",
    "mds = manifold.MDS(n_components=2, dissimilarity=\"precomputed\", random_state=6)\n",
    "\n",
    "# Compute MDS and extract the coordinates of the points\n",
    "results = mds.fit(distMatDeg1)\n",
    "coords = results.embedding_\n",
    "\n",
    "plt.scatter(coords[:,0],coords[:,1], c=labels, cmap = 'hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points above are colored by the class they belong to. We see that shapes of the same class are (roughly) clustered close together. This qualitatively tells us that bottleneck distance is doing a good job of distinguishing the shapes!\n",
    "\n",
    "If you would like to see how to make this more precise, go on to the following optional section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Scores (Optional)\n",
    "\n",
    "This section will use some ideas from the field of machine learning. Things are mostly explained in the text, but please feel free to flag me down if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to test whether bottleneck distance works as a good classifier. To get a sense of what \"good\" means, we would like to compare to other standard classification techniques. Most standard algorithms take vectors as input, so let's reshape our data to put it in vector form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [shapeSamples[j].reshape(200,) for j in range(num_samp)]\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we can compare to is *Procrustes distance*. This will take a pair of shapes, try to rotate and translate one of them so that they align as much as possible, then take sum of squared distances between aligned points. I want to use Procrustes distance as a callable function later, so I will define it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import procrustes\n",
    "\n",
    "def procDist(X,Y):\n",
    "    X1 = X.reshape(100,2)\n",
    "    Y1 = Y.reshape(100,2)\n",
    "    m1, m2, disp = procrustes(shapeSamples[j], shapeSamples[k])\n",
    "    return disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the Procrustes distance matrix for our shape data, as we did above for bottleneck distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distMatProcrustes = np.zeros([num_samp,num_samp])\n",
    "\n",
    "for j in range(num_samp):\n",
    "    for k in range(j+1,num_samp):\n",
    "        distMatProcrustes[j,k] = procDist(X[j],X[k])\n",
    "\n",
    "distMatProcrustes = distMatProcrustes + np.transpose(distMatProcrustes)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(distMatProcrustes)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use a callable function for bottleneck distance, so I will define one now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneckDist(X,Y):\n",
    "    X1 = X.reshape(100,2)\n",
    "    Y1 = Y.reshape(100,2)\n",
    "    dgm1 = ripser(X1)['dgms'][1]\n",
    "    dgm2 = ripser(Y1)['dgms'][1]\n",
    "    return persim.bottleneck(dgm1, dgm2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test classification rate, we split our data into a training set and a testing set. This means we pick off 80% of the shapes from the whole collection to 'train' our classification model. We will then test the performance of our classification model on the 'test' set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use $k$-Nearest Neighbors classification. This model is very simple: to classify a point in the test set, we find its $k$ closest (with respect to whichever metric we are using) neighbors in the training set. Those neighbors have labels, and the majority label is assigned to the test point.\n",
    "\n",
    "We will test the classification performance of bottleneck distance and of procrustes distance. Notice that the `scikit-learn` implementation of $k$-NN allows us to use callable functions for our distance metric. This is why I defined these earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the bottleneck distance model and fit\n",
    "neighBottleneck = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree', metric = bottleneckDist)\n",
    "neighBottleneck.fit(X_train, y_train) \n",
    "\n",
    "# Define the Procrustes distance model and fit\n",
    "neighProc = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree', metric = procDist)\n",
    "neighProc.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find the classification rate for each metric on the testing set. This takes a while, by the nature of $k$NN, the fact that we are using callable functions as our metrics, and the slowness of the bottleneck distance computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighBottleneck.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighProc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that bottleneck distance performs relatively well! This is made more apparent by the quite poor performance of Procrustes distance, which most would consider to be the \"standard\" metric to use here.\n",
    "\n",
    "Let's look at the MDS plot of the Procrustes distance matrix to see what is going wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = mds.fit(distMatProcrustes)\n",
    "coords = results.embedding_\n",
    "\n",
    "plt.scatter(coords[:,0],coords[:,1], c=labels, cmap = 'hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what was predicted correctly/incorrectly, we can look at the *confusion matrix*. For a general multiclass classification problem with labels $0,1,\\ldots,K$, the confusion matrix is the $(K+1) \\times (K+1)$ matrix\n",
    "$$\n",
    "C = (C_{ij}) = \\left(\\begin{array}{cccc}\n",
    "C_{00} & C_{01} & \\cdots & C_{0K} \\\\\n",
    "C_{10} & C_{11} & \\cdots & C_{1K} \\\\\n",
    "\\vdots & \\vdots & & \\vdots \\\\\n",
    "C_{K0} & C_{K1} & \\cdots & C_{KK} \\end{array}\\right)\n",
    "$$\n",
    "with entry $C_{ij}$ giving the number of observations known to be in group $i$ and predicted to be in group $j$.\n",
    "\n",
    "This can be computed via `scikit-learn` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "predictedBottleneck = neighBottleneck.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, predictedBottleneck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedProc = neighProc.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, predictedProc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently Procrustes distance was extrememly confused by Shape 2!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "If you are familiar with Machine Learning techniques, see if you can create a model which outperforms TDA on this dataset. This is *certainly* possible, but I think it requires some cleverness. I.e., I don't believe that applying basic `scikit-learn` algorithms directly will do the trick."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
